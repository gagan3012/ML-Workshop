# ML Workshop for NLP using HuggingFace

This workshop consists of experimenting with 'straight out-of-the-box' functionalities of HuggingFace Transformers, without using any data, training, pre-traing or fine-tuning of any sorts. It mostly represents the wide range of tasks for which Tranformers can be used and their precision in doing so.

### To understand how the pretrained models are used click down here:

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gagan3012/huggingface/blob/master/WorkshopNotebook.ipynb)
 
### To run the Dashboard

```
pip install -r requirements.txt 

streamlit run app.py
```

### Dashbaord Preview

[![qna](images/qna.png')]

[![qna](images/senti.png')]


